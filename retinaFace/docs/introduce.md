## 1.retinaFace设计思路

### 1.1 先验框(prior box)

​        借鉴anchor的理念，为feature map的每个单元设置长宽比相同的先验框(人脸长宽基本相同，而其它目标检测领域需要设置不同的长宽比)。借用SSD相关图。每个单元会设置多个先验框，其尺度和长宽比存在差异，如图所示，可以看到每个单元使用了4个不同的先验框，图片中猫和狗分别采用最适合它们形状的先验框来进行训练，后面会详细讲解训练过程中的先验框匹配原则。

![](img\img1.jpg)

对于每个单元的每个先验框，其都输出一套独立的检测值，对应一个边界框，主要分为两个部分。

第一部分是各个类别的置信度，背景也当做了一个特殊的类别，如果检测目标共有c个类别，则需要预测c+1个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。后面当我们说c个类别置信度时，请记住里面包含背景那个特殊的类别，即真实的检测类别只有c−1个。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标。
第二部分是边界框的location包含4个值$(cx, cy, w, h)$，分别表示边界框的中心坐标以及宽高。假设先验框位置为$p = (p^{cx}, p^{cy}, p^{w}, p^{h})$，其对应的边界框为$b = (b^{cx}, b^{cy}, b^{w}, b^{h})$，那么边界框的预测值$l = (l^{cx}, l^{cy}, l^{w}, l^{h})$

计算公式如下：
$$
\begin{align*}
l^{cx} &= (b^{cx} - p^{cx})/p^{w}, l^{cy} = (b^{cy} - p^{cy})/p^{h}\\
l^{w} &= log(b^{w} / p^{w}), l^{h} = log(b^{h} / p^{h})
\end{align*}
$$
习惯上，称上述过程为边界框的编码(encode)，预测时需要反向这个过程，即解码(decode)，从预测值$l$到边界框的真实位置$b$

计算公式如下：
$$
\begin{align*}
b^{cx} &= p^{w}l^{cx} + p^{cx}, b^{cy} = p^{h}l^{cy} + p^{cy}\\
b^{w} &= p^{w}exp(l^{w}), b^{h} = p^{h}exp(l^{h})
\end{align*}
$$
在训练中使用了一些trick，那就是设置variance超参数来调整检测值，此时边界框的编码和解码过程需要更新如下：
$$
\begin{align*}
b^{cx} &= p^{w}(variance[0]*l^{cx}) + p^{cx}, b^{cy} = p^{h}(variance[1]*l^{cy}) + p^{cy}\\
b^{w} &= p^{w}exp(variance[2]*l^{w}), b^{h} = p^{h}exp(variance[3]*l^{h})
\end{align*}
$$
对于一个大小$m×n$的特征图，共有$mn$个单元，每个单元设置的先验框数目记为$k$，那么每个单元共需要$(c+4)k$个预测值，所有的单元共需要$(c+4)kmn$个预测值。



## 2.训练过程

### 2.1先验框匹配

​        在训练过程中，首先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。先验框与ground truth的匹配有两个原则：

第一个原则：对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本，反之，若一个先验框没有与任何ground truth进行匹配，那么该先验框只能与背景匹配，就是负样本。一个图片中ground truth是非常少的， 而先验框却很多，很多先验框会是负样本，正负样本极其不平衡。

第二个原则：对于剩余的未匹配先验框，若某个ground truth的IOU大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配。

​        尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，采用了hard negative mining，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。

### 2.2损失函数

